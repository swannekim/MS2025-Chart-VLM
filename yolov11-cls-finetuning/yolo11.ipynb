{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Prerequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## conda virtualenv ìƒì„±\n",
        "- Python 3.13.1ì€ AzureMLì˜ ì¼ë¶€ ì¢…ì†ì„±ì—ì„œ ë¬¸ì œ ë°œìƒ. (ì°¸ê³ : https://docs.ultralytics.com/ko/guides/azureml-quickstart/#quickstart-from-terminal)\n",
        "- íŒŒì¼ ê²½ë¡œ: Users/t-yooyeunkim/ultralytics-yolo/yolo11.ipynb\n",
        "```bash\n",
        "conda create --name yolo11env2 -y python=3.12\n",
        "conda activate yolo11env2 # conda deactivate\n",
        "conda install pip -y\n",
        "```\n",
        "```bash\n",
        "pip install ipykernel\n",
        "python -m ipykernel install --user --name=yolo11env2 --display-name \"Python (yolo11env2)\"\n",
        "```\n",
        "- Jupyter ìƒë‹¨ ë©”ë‰´ â†’ Kernel â†’ Change Kernel â†’ Python (yolo11env2) ì„ íƒ\n",
        "```bash\n",
        "cd ultralytics\n",
        "pip install -r requirements.txt\n",
        "pip install ultralytics onnx opencv-python matplotlib azure-ai-ml azureml.fsspec datasets fiftyone pillow tqdm python-dotenv\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1756274042549
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/yolo11env2/bin/python\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.executable)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## GPU ë° ëª¨ë¸ ì‘ì—…ìˆ˜í–‰ í™•ì¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1756274061322
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Torch CUDA: True CUDA device: NVIDIA H100 NVL\n",
            "Linux-6.8.0-1030-azure-x86_64-with-glibc2.35\n"
          ]
        }
      ],
      "source": [
        "import torch, platform\n",
        "print(\"Torch CUDA:\", torch.cuda.is_available(), \"CUDA device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else None)\n",
        "print(platform.platform())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "```bash\n",
        "yolo classify predict model=yolo11n-cls.pt source='https://ultralytics.com/images/bus.jpg'\n",
        "```\n",
        "```bash\n",
        "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-cls.pt to 'yolo11n-cls.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.5/5.5MB 32.7MB/s 0.2s\n",
        "Ultralytics 8.3.186 ğŸš€ Python-3.12.11 torch-2.8.0+cu128 CUDA:0 (NVIDIA H100 NVL, 95248MiB)\n",
        "YOLO11n-cls summary (fused): 47 layers, 2,807,024 parameters, 0 gradients, 4.2 GFLOPs\n",
        "\n",
        "Downloading https://ultralytics.com/images/bus.jpg to 'bus.jpg': 100% â”â”â”â”â”â”â”â”â”â”â”â” 134.2/134.2KB 1.5MB/s 0.1s\n",
        "image 1/1 /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/bus.jpg: 224x224 minibus 0.57, police_van 0.34, trolleybus 0.04, recreational_vehicle 0.01, streetcar 0.01, 2.3ms\n",
        "Speed: 52.8ms preprocess, 2.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
        "Results saved to runs/classify/predict\n",
        "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ í™•ì¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1756274176187
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## data í´ë” ìƒì„±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1756274235823
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CWD: /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11\n",
            "âœ… made folders under ./ultralytics-yolo/data/...\n",
            "train chart: 0 nonchart: 0\n",
            "val chart: 0 nonchart: 0\n",
            "test chart: 0 nonchart: 0\n"
          ]
        }
      ],
      "source": [
        "# 1) ë…¸íŠ¸ë¶ í´ë”ë¡œ ì´ë™\n",
        "import os, pathlib\n",
        "os.chdir(\"yolov11\")  # í˜„ì¬ CWD ê¸°ì¤€ í•˜ìœ„ í´ë”ë¡œ ì´ë™\n",
        "print(\"CWD:\", os.getcwd())\n",
        "# 2) data/ ë¼ˆëŒ€ ë§Œë“¤ê¸°\n",
        "for split in [\"train\",\"val\",\"test\"]:\n",
        "    for cls in [\"chart\",\"nonchart\"]:\n",
        "        pathlib.Path(f\"data/{split}/{cls}\").mkdir(parents=True, exist_ok=True)\n",
        "print(\"âœ… made folders under ./ultralytics-yolo/data/...\")\n",
        "\n",
        "# 3) ìƒ˜í”Œ ê°œìˆ˜ í™•ì¸ í•¨ìˆ˜\n",
        "def count_images(p):\n",
        "    return sum(len(files) for _,_,files in os.walk(p))\n",
        "\n",
        "for split in [\"train\",\"val\",\"test\"]:\n",
        "    print(split, \"chart:\", count_images(f\"data/{split}/chart\"),\n",
        "                 \"nonchart:\", count_images(f\"data/{split}/nonchart\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## ë°ì´í„° ì´ë¯¸ì§€íŒŒì¼ ì±„ìš°ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1756274254683
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BASE: LocalUpload/e842e34bb09e3a842dfe9e69246792751cdf9522462626cbf40335d67174ea4e/ChartQA-Dataset\n",
            "ROOT: ['LocalUpload/e842e34bb09e3a842dfe9e69246792751cdf9522462626cbf40335d67174ea4e/ChartQA-Dataset/test/', 'LocalUpload/e842e34bb09e3a842dfe9e69246792751cdf9522462626cbf40335d67174ea4e/ChartQA-Dataset/train/', 'LocalUpload/e842e34bb09e3a842dfe9e69246792751cdf9522462626cbf40335d67174ea4e/ChartQA-Dataset/val/']\n",
            "SAMPLE: ['LocalUpload/e842e34bb09e3a842dfe9e69246792751cdf9522462626cbf40335d67174ea4e/ChartQA-Dataset/train/png/00006834003065.png', 'LocalUpload/e842e34bb09e3a842dfe9e69246792751cdf9522462626cbf40335d67174ea4e/ChartQA-Dataset/train/png/00035547003867.png', 'LocalUpload/e842e34bb09e3a842dfe9e69246792751cdf9522462626cbf40335d67174ea4e/ChartQA-Dataset/train/png/00035547003876.png', 'LocalUpload/e842e34bb09e3a842dfe9e69246792751cdf9522462626cbf40335d67174ea4e/ChartQA-Dataset/train/png/00097754005965.png', 'LocalUpload/e842e34bb09e3a842dfe9e69246792751cdf9522462626cbf40335d67174ea4e/ChartQA-Dataset/train/png/00108924005661.png']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Overriding of current TracerProvider is not allowed\n",
            "Overriding of current LoggerProvider is not allowed\n",
            "Overriding of current MeterProvider is not allowed\n",
            "Attempting to instrument while already instrumented\n",
            "Attempting to instrument while already instrumented\n",
            "Attempting to instrument while already instrumented\n"
          ]
        }
      ],
      "source": [
        "from azureml.fsspec import AzureMachineLearningFileSystem as AMLFS\n",
        "import os, pathlib\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "# blobstore ê²½ë¡œ\n",
        "blob_prefix = os.getenv(\"BLOB_PREFIX\")\n",
        "\n",
        "fs = AMLFS(blob_prefix)  # ì¸ì¦ì€ CIì—ì„œ ìë™ìœ¼ë¡œ ë¶™ìŒ (ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ê¶Œí•œ í•„ìš”)\n",
        "\n",
        "# BASE: datastore ê¸°ì¤€ ì ˆëŒ€ ê²½ë¡œ(ChartQA-Datasetê¹Œì§€ í¬í•¨)\n",
        "BASE = blob_prefix.split(\"/paths/\")[1].strip(\"/\")  # 'LocalUpload/.../ChartQA-Dataset'\n",
        "print(\"BASE:\", BASE)\n",
        "\n",
        "print(\"ROOT:\", fs.ls(BASE)[:5])                 # ['.../ChartQA-Dataset/train/', ...]: ['train/', 'val/', 'test/'] ì‹ìœ¼ë¡œ ë– ì•¼ ì •ìƒ\n",
        "print(\"SAMPLE:\", fs.ls(f\"{BASE}/train/png\")[:5])  # ì´ë¯¸ì§€ ëª©ë¡ì´ ë‚˜ì™€ì•¼ ì •ìƒ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### chart data: ë°ì´í„° ì‘ì—… > íƒ‘ì¬ > ì‚¬ìš©"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1756274262481
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mount contains: [PosixPath('/home/azureuser/cloudfiles/data/uri/chartqa_dataset/test'), PosixPath('/home/azureuser/cloudfiles/data/uri/chartqa_dataset/train'), PosixPath('/home/azureuser/cloudfiles/data/uri/chartqa_dataset/val')]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "MOUNT = Path(\"/home/azureuser/cloudfiles/data/uri/chartqa_dataset\")  # Studioê°€ íƒ‘ì¬í•œ ê²½ë¡œ\n",
        "print(\"mount contains:\", list(MOUNT.iterdir()))  # ['train','val','test'] í™•ì¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1756274265549
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train: linked data/train/chart -> /home/azureuser/cloudfiles/data/uri/chartqa_dataset/train/png\n",
            "val: linked data/val/chart -> /home/azureuser/cloudfiles/data/uri/chartqa_dataset/val/png\n",
            "test: linked data/test/chart -> /home/azureuser/cloudfiles/data/uri/chartqa_dataset/test/png\n"
          ]
        }
      ],
      "source": [
        "# data/{split}/chart ë¥¼ 'í´ë” ë§í¬'ë¡œ êµì²´\n",
        "for split in [\"train\",\"val\",\"test\"]:\n",
        "    src_dir = MOUNT / split / \"png\"          # ì›ë³¸ ì°¨íŠ¸ ì´ë¯¸ì§€ í´ë”\n",
        "    dst_root = Path(\"data\") / split\n",
        "    dst_root.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    link = dst_root / \"chart\"\n",
        "    if link.exists() or link.is_symlink():\n",
        "        if link.is_dir() and not link.is_symlink():\n",
        "            # ê¸°ì¡´ì— ë³µì‚¬í•œ ê²Œ ìˆìœ¼ë©´ ë°±ì—…/ì‚­ì œ íƒ1\n",
        "            os.system(f\"rm -rf '{link}'\")    # í•„ìš” ì‹œ ì•ˆì „í•˜ê²Œ ë°±ì—… í›„ ì‚­ì œ\n",
        "        else:\n",
        "            link.unlink()\n",
        "    os.symlink(src_dir, link)                # âœ… í´ë” ì „ì²´ë¥¼ ë§í¬ (ì¦‰ì‹œ ë)\n",
        "    print(f\"{split}: linked {link} -> {src_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1756274272725
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train chart: 18317 nonchart: 0\n",
            "val chart: 1056 nonchart: 0\n",
            "test chart: 1509 nonchart: 0\n"
          ]
        }
      ],
      "source": [
        "for split in [\"train\",\"val\",\"test\"]:\n",
        "    print(split, \"chart:\", count_images(f\"data/{split}/chart\"),\n",
        "                 \"nonchart:\", count_images(f\"data/{split}/nonchart\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### nonchart data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1756274935078
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/yolo11env2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading split 'validation' to '_foz_cache/coco-2017/validation' if necessary\n",
            "Downloading annotations to '_foz_cache/coco-2017/tmp-download/annotations_trainval2017.zip'\n",
            " 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|    1.9Gb/1.9Gb [4.8s elapsed, 0s remaining, 449.0Mb/s]       \n",
            "Extracting annotations to '_foz_cache/coco-2017/raw/instances_val2017.json'\n",
            "Downloading 5000 images\n",
            " 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [1.5m elapsed, 0s remaining, 52.8 images/s]      \n",
            "Writing annotations to '_foz_cache/coco-2017/validation/labels.json'\n",
            "Dataset info written to '_foz_cache/coco-2017/info.json'\n",
            "Loading 'coco-2017' split 'validation'\n",
            " 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [844.6ms elapsed, 0s remaining, 5.9K samples/s]      \n",
            "Dataset 'coco_val_5k' created\n",
            "train nonchart: 3500 (symlink: 3500 copy: 0 )\n",
            "val   nonchart: 750 (symlink: 750 copy: 0 )\n",
            "test  nonchart: 750 (symlink: 750 copy: 0 )\n",
            "train chart: 18317 nonchart: 3500\n",
            "val chart: 1056 nonchart: 750\n",
            "test chart: 1509 nonchart: 750\n"
          ]
        }
      ],
      "source": [
        "# === COCO 2017 val(5K) â†’ data/{train,val,test}/nonchart ì±„ìš°ê¸° ===\n",
        "# - 5,000ì¥ ì „ë¶€ ì‚¬ìš©\n",
        "# - ë¶„ë°°: 70%/15%/15% = 3500 / 750 / 750\n",
        "# - symlink ìš°ì„ , ì‹¤íŒ¨ ì‹œ copy í´ë°±\n",
        "\n",
        "import os, shutil, random\n",
        "from pathlib import Path\n",
        "import fiftyone as fo\n",
        "import fiftyone.zoo as foz\n",
        "\n",
        "# 0) ëª©í‘œ ê°œìˆ˜(ê³ ì • 5k ë¶„í• )\n",
        "TARGET = {\"train\": 3500, \"val\": 750, \"test\": 750}\n",
        "\n",
        "# 1) dataset zoo ìºì‹œ(ì¬ì‹¤í–‰ ì‹œ ì¬ë‹¤ìš´ë¡œë“œ ë°©ì§€)\n",
        "fo.config.dataset_zoo_dir = \"_foz_cache\"\n",
        "Path(fo.config.dataset_zoo_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 2) COCO 2017 validation 5k ë¡œë“œ(ì „ì²´)\n",
        "# ds = foz.load_zoo_dataset(\n",
        "#     \"coco-2017\",\n",
        "#     split=\"validation\",\n",
        "#     max_samples=5000,\n",
        "#     shuffle=True,\n",
        "#     dataset_dir=\"_foz_cache/coco_val_5k\",\n",
        "#     drop_existing_dataset=True,\n",
        "# )\n",
        "\n",
        "# âœ… dataset_dir ì œê±°, dataset_name ì‚¬ìš©, ë¼ë²¨ ë¯¸ë¡œë”©\n",
        "ds = foz.load_zoo_dataset(\n",
        "    \"coco-2017\",\n",
        "    split=\"validation\",\n",
        "    max_samples=5000,\n",
        "    shuffle=True,\n",
        "    dataset_name=\"coco_val_5k\",\n",
        "    drop_existing_dataset=True,\n",
        "    label_types=[],          # â† annotation ë¯¸ë¡œë”© (ì´ë¯¸ì§€ ê²½ë¡œë§Œ)\n",
        ")\n",
        "\n",
        "paths = ds.values(\"filepath\")\n",
        "random.seed(42)\n",
        "random.shuffle(paths)\n",
        "\n",
        "# 3) 70/15/15 ë¶„í• \n",
        "train_paths = paths[:TARGET[\"train\"]]\n",
        "val_paths   = paths[TARGET[\"train\"]:TARGET[\"train\"]+TARGET[\"val\"]]\n",
        "test_paths  = paths[TARGET[\"train\"]+TARGET[\"val\"]:TARGET[\"train\"]+TARGET[\"val\"]+TARGET[\"test\"]]\n",
        "\n",
        "def place(paths, dst_dir, prefer_symlink=True):\n",
        "    dst = Path(dst_dir); dst.mkdir(parents=True, exist_ok=True)\n",
        "    ln = cp = 0\n",
        "    for src in paths:\n",
        "        src = Path(src)\n",
        "        out = dst / src.name\n",
        "        if out.exists():  # ì¤‘ë³µ ë°©ì§€\n",
        "            continue\n",
        "        if prefer_symlink:\n",
        "            try:\n",
        "                os.symlink(src, out)  # ê°€ì¥ ë¹ ë¦„\n",
        "                ln += 1\n",
        "                continue\n",
        "            except Exception:\n",
        "                pass\n",
        "        shutil.copy2(src, out)        # í´ë°±\n",
        "        cp += 1\n",
        "    return ln, cp\n",
        "\n",
        "# 4) ì‹¤ì œ ë°°ì¹˜\n",
        "ln, cp = place(train_paths, \"data/train/nonchart\"); print(\"train nonchart:\", len(train_paths), \"(symlink:\", ln, \"copy:\", cp, \")\")\n",
        "ln, cp = place(val_paths,   \"data/val/nonchart\");   print(\"val   nonchart:\", len(val_paths),   \"(symlink:\", ln, \"copy:\", cp, \")\")\n",
        "ln, cp = place(test_paths,  \"data/test/nonchart\");  print(\"test  nonchart:\", len(test_paths),  \"(symlink:\", ln, \"copy:\", cp, \")\")\n",
        "\n",
        "# 5) ìµœì¢… ê°œìˆ˜ í™•ì¸\n",
        "def count_images(p): \n",
        "    p = Path(p)\n",
        "    return sum(1 for x in p.glob(\"*\") if x.suffix.lower() in {\".jpg\",\".jpeg\",\".png\",\".webp\"})\n",
        "for split in [\"train\",\"val\",\"test\"]:\n",
        "    print(split, \"chart:\", count_images(f\"data/{split}/chart\"),\n",
        "                 \"nonchart:\", count_images(f\"data/{split}/nonchart\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1756275503249
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "target(chart): {'train': 18317, 'val': 1056, 'test': 1509} \n",
            "current(nonchart): {'train': 3500, 'val': 750, 'test': 750} \n",
            "need: {'train': 14817, 'val': 306, 'test': 759}\n",
            "[train] +2000 saved (total 2000/14817)\n",
            "[train] +2000 saved (total 4000/14817)\n",
            "[train] +2000 saved (total 6000/14817)\n",
            "[train] +2000 saved (total 8000/14817)\n",
            "[train] +2000 saved (total 10000/14817)\n",
            "[train] +2000 saved (total 12000/14817)\n",
            "[train] +817 saved (total 14817/14817)\n",
            "[train] done. saved_total=14817, out=data/train/nonchart\n",
            "[val] +306 saved (total 306/306)\n",
            "[val] done. saved_total=306, out=data/val/nonchart\n",
            "[test] +759 saved (total 759/759)\n",
            "[test] done. saved_total=759, out=data/test/nonchart\n",
            "train chart: 18317 nonchart: 18317\n",
            "val chart: 1056 nonchart: 1056\n",
            "test chart: 1509 nonchart: 1509\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "train save batch#0 (0/14817): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:36<00:00, 54.52it/s]\n",
            "train save batch#6 (12000/14817):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1066/2000 [00:19<00:18, 49.20it/s]\rtrain save batch#7 (14000/14817):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 695/817 [00:11<00:01, 65.43it/s]\rval save batch#0 (0/306):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 152/306 [00:02<00:02, 56.71it/s]"
          ]
        }
      ],
      "source": [
        "# DocLayNet â†’ nonchart (streaming=True + ë³‘ë ¬ ì €ì¥ + ì¬ì‹¤í–‰ ì•ˆì „)\n",
        "\n",
        "import os, itertools, random\n",
        "from pathlib import Path\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from PIL import Image\n",
        "\n",
        "BASE    = Path(\"data\")\n",
        "SPLITS  = [\"train\",\"val\",\"test\"]\n",
        "SPLIT_MAP = {\"val\": \"validation\"}     # DocLayNet ë¶„í• ëª… ë§¤í•‘\n",
        "WORKERS = 32        # CI ì½”ì–´ì— ë§ì¶° ì¡°ì •\n",
        "CHUNK   = 2000      # í•œ ë²ˆì— ë°›ì•„ ì €ì¥í•  ìƒ˜í”Œ ìˆ˜(ë©”ëª¨ë¦¬/ë””ìŠ¤í¬ ì—¬ìœ ì— ë§ê²Œ)\n",
        "\n",
        "# ì €ì¥ í¬ë§·: 'png' ë˜ëŠ” 'jpeg' (jpegê°€ ë””ìŠ¤í¬ í›¨ì”¬ ì ˆì•½)\n",
        "SAVE_FMT = \"png\"    # í•„ìš”í•˜ë©´ 'jpeg' ë¡œ ë³€ê²½\n",
        "JPEG_QUALITY = 90\n",
        "\n",
        "def count_images(dirpath: Path):\n",
        "    exts = {\".png\",\".jpg\",\".jpeg\",\".webp\"}\n",
        "    return sum(1 for p in dirpath.glob(\"*\") if p.suffix.lower() in exts)\n",
        "\n",
        "# í˜„ì¬ chart/nonchart ê°œìˆ˜ â†’ ë¶€ì¡±ë¶„ ê³„ì‚°(ì°¨íŠ¸ì™€ ë™ìˆ˜ ë§ì¶”ê¸°)\n",
        "target  = {s: count_images(BASE/s/\"chart\")    for s in SPLITS}\n",
        "current = {s: count_images(BASE/s/\"nonchart\") for s in SPLITS}\n",
        "need    = {s: max(0, target[s]-current[s])    for s in SPLITS}\n",
        "print(\"target(chart):\", target, \"\\ncurrent(nonchart):\", current, \"\\nneed:\", need)\n",
        "\n",
        "def _dst_path(out_dir: Path, idx: int):\n",
        "    ext = \".jpg\" if SAVE_FMT == \"jpeg\" else \".png\"\n",
        "    return out_dir / f\"doclaynet_{idx:07d}{ext}\"\n",
        "\n",
        "def save_one(out_dir: Path, idx: int, pil_img: Image.Image):\n",
        "    dst = _dst_path(out_dir, idx)\n",
        "    if dst.exists():\n",
        "        return \"skip\"\n",
        "    if SAVE_FMT == \"jpeg\":\n",
        "        pil_img.convert(\"RGB\").save(dst, format=\"JPEG\", quality=JPEG_QUALITY, optimize=True)\n",
        "    else:\n",
        "        pil_img.save(dst)  # PNG\n",
        "    return \"save\"\n",
        "\n",
        "def fill_streaming(split: str, remaining: int, workers: int = WORKERS, chunk: int = CHUNK):\n",
        "    if remaining <= 0:\n",
        "        print(f\"[{split}] already balanced\")\n",
        "        return\n",
        "    hf_split = SPLIT_MAP.get(split, split)  # 'val' -> 'validation'\n",
        "    out_dir = BASE/split/\"nonchart\"; out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„°ì…‹(ìºì‹œ í¬ê²Œ ì•ˆ ì”€)\n",
        "    ds = load_dataset(\"ds4sd/DocLayNet-v1.2\", split=hf_split, streaming=True)\n",
        "    it = iter(ds)\n",
        "\n",
        "    saved_total = 0\n",
        "    idx_base = count_images(out_dir)  # ëŒ€ëµì  ì‹œì‘ ì¸ë±ìŠ¤(ì¶©ëŒ ì˜ˆë°©ìš©)\n",
        "    batch_no = 0\n",
        "\n",
        "    while saved_total < remaining:\n",
        "        k = min(chunk, remaining - saved_total)\n",
        "        batch = list(itertools.islice(it, k))\n",
        "        if not batch:\n",
        "            print(f\"[{split}] DocLayNet ê³ ê°ˆ: {saved_total}/{remaining} ì €ì¥ í›„ ì¤‘ë‹¨\")\n",
        "            break\n",
        "\n",
        "        def task(en):\n",
        "            i, ex = en\n",
        "            return save_one(out_dir, idx_base + saved_total + i, ex[\"image\"])\n",
        "\n",
        "        with ThreadPoolExecutor(max_workers=workers) as pool:\n",
        "            futures = [pool.submit(task, (i, ex)) for i, ex in enumerate(batch)]\n",
        "            for _ in tqdm(as_completed(futures), total=len(futures),\n",
        "                          desc=f\"{split} save batch#{batch_no} ({saved_total}/{remaining})\"):\n",
        "                pass\n",
        "\n",
        "        # ì €ì¥/ìŠ¤í‚µ ì§‘ê³„\n",
        "        saves = sum(1 for f in futures if f.result() == \"save\")\n",
        "        saved_total += saves\n",
        "        batch_no += 1\n",
        "        print(f\"[{split}] +{saves} saved (total {saved_total}/{remaining})\")\n",
        "\n",
        "    print(f\"[{split}] done. saved_total={saved_total}, out={out_dir}\")\n",
        "\n",
        "# ì‹¤í–‰\n",
        "for s in SPLITS:\n",
        "    fill_streaming(s, need[s], workers=WORKERS, chunk=CHUNK)\n",
        "\n",
        "# ìµœì¢… ê°œìˆ˜ í™•ì¸\n",
        "for s in SPLITS:\n",
        "    print(s, \"chart:\", count_images(BASE/s/\"chart\"),\n",
        "             \"nonchart:\", count_images(BASE/s/\"nonchart\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1756275504331
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train chart: 18317 nonchart: 18317\n",
            "val chart: 1056 nonchart: 1056\n",
            "test chart: 1509 nonchart: 1509\n"
          ]
        }
      ],
      "source": [
        "# ìµœì¢… ê°œìˆ˜ í™•ì¸\n",
        "def count_images(p): \n",
        "    p = Path(p)\n",
        "    return sum(1 for x in p.glob(\"*\") if x.suffix.lower() in {\".jpg\",\".jpeg\",\".png\",\".webp\"})\n",
        "for split in [\"train\",\"val\",\"test\"]:\n",
        "    print(split, \"chart:\", count_images(f\"data/{split}/chart\"),\n",
        "                 \"nonchart:\", count_images(f\"data/{split}/nonchart\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## yaml íŒŒì¼ ìƒì„±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1756275532379
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train/chart: 18317 images\n",
            "train/nonchart: 18317 images\n",
            "val/chart: 1056 images\n",
            "val/nonchart: 1056 images\n",
            "test/chart: 1509 images\n",
            "test/nonchart: 1509 images\n",
            "\n",
            "=== data.yaml ===\n",
            "train: /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/data/train\n",
            "val: /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/data/val\n",
            "test: /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/data/test\n",
            "names:\n",
            "  0: chart\n",
            "  1: nonchart\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os, yaml, pathlib\n",
        "\n",
        "DATA_ROOT = \"data\"  # data/{train,val,test}/{chart,nonchart}\n",
        "\n",
        "def real(p):  # symlink ì•ˆì „í•˜ê²Œ ì ˆëŒ€ê²½ë¡œë¡œ ê³ ì •\n",
        "    return os.path.realpath(p)\n",
        "\n",
        "# sanity check: ê° splitì— ìµœì†Œ 1ì¥ì”© ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸\n",
        "def count_imgs(d):\n",
        "    exts = {\".jpg\",\".jpeg\",\".png\",\".webp\"}\n",
        "    d = pathlib.Path(d)\n",
        "    return sum(1 for x in d.glob(\"*\") if x.suffix.lower() in exts)\n",
        "\n",
        "for split in [\"train\",\"val\",\"test\"]:\n",
        "    for cls in [\"chart\",\"nonchart\"]:\n",
        "        n = count_imgs(f\"{DATA_ROOT}/{split}/{cls}\")\n",
        "        assert n > 0, f\"[EMPTY] {split}/{cls} ë¹„ì–´ìˆìŒ. ë¨¼ì € ì±„ì›Œì£¼ì„¸ìš”.\"\n",
        "        print(f\"{split}/{cls}: {n} images\")\n",
        "\n",
        "data_yaml = {\n",
        "    # Ultralytics ë¶„ë¥˜ëŠ” ê° split ë””ë ‰í† ë¦¬ í•˜ìœ„ì˜ í´ë”ëª…ì´ í´ë˜ìŠ¤ê°€ ë¨\n",
        "    \"train\": real(f\"{DATA_ROOT}/train\"),\n",
        "    \"val\":   real(f\"{DATA_ROOT}/val\"),\n",
        "    \"test\":  real(f\"{DATA_ROOT}/test\"),\n",
        "\n",
        "    # namesëŠ” ëª…ì‹œí•´ë‘ë©´ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ê°€ ê³ ì •ë¼ì„œ ì•ˆì „í•¨(0: chart, 1: nonchart)\n",
        "    \"names\": {0: \"chart\", 1: \"nonchart\"}\n",
        "    # \"names\": [\"chart\", \"nonchart\"],  # ë¦¬ìŠ¤íŠ¸ë¡œ ê³ ì •\n",
        "}\n",
        "\n",
        "pathlib.Path(DATA_ROOT).mkdir(parents=True, exist_ok=True)\n",
        "with open(f\"{DATA_ROOT}/data.yaml\",\"w\") as f:\n",
        "    yaml.safe_dump(data_yaml, f, sort_keys=False, allow_unicode=True)\n",
        "\n",
        "print(\"\\n=== data.yaml ===\")\n",
        "print(open(f\"{DATA_ROOT}/data.yaml\",\"r\").read())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Data Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1756275539590
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train classes: ['chart', 'nonchart']\n",
            " - train/chart     exists=True is_dir=True is_symlink=True\n",
            " - train/nonchart  exists=True is_dir=True is_symlink=False\n",
            "val classes: ['chart', 'nonchart']\n",
            " - val/chart     exists=True is_dir=True is_symlink=True\n",
            " - val/nonchart  exists=True is_dir=True is_symlink=False\n",
            "test classes: ['chart', 'nonchart']\n",
            " - test/chart     exists=True is_dir=True is_symlink=True\n",
            " - test/nonchart  exists=True is_dir=True is_symlink=False\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "def classes(p): \n",
        "    p = Path(p)\n",
        "    return [d.name for d in p.iterdir() if d.is_dir()]\n",
        "\n",
        "for split in [\"train\",\"val\",\"test\"]:\n",
        "    cls = classes(f\"data/{split}\")\n",
        "    print(f\"{split} classes:\", cls)  # ë°˜ë“œì‹œ ['chart','nonchart'] ë‘ ê°œê°€ ë³´ì—¬ì•¼ í•©ë‹ˆë‹¤.\n",
        "\n",
        "    for c in [\"chart\",\"nonchart\"]:\n",
        "        d = Path(f\"data/{split}/{c}\")\n",
        "        print(f\" - {split}/{c:9s} exists={d.exists()} is_dir={d.is_dir()} is_symlink={d.is_symlink()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1756275547920
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train chart -> True 00006834003065.png\n",
            "train nonchart -> True 000000000139.jpg\n",
            "val chart -> True 00006834003066.png\n",
            "val nonchart -> True 000000000785.jpg\n",
            "test chart -> True 00339007006077.png\n",
            "test nonchart -> True 000000001584.jpg\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "VALID_EXT = {\".bmp\",\".jpg\",\".jpeg\",\".png\",\".tif\",\".tiff\",\".dng\",\".webp\",\".mpo\"}\n",
        "\n",
        "def has_any_file(dirpath: Path):\n",
        "    with os.scandir(dirpath) as it:          # scandirê°€ globë³´ë‹¤ ë¹ ë¥´ê³  ê°€ë³ìŠµë‹ˆë‹¤\n",
        "        for e in it:\n",
        "            if e.is_file() and Path(e.name).suffix.lower() in VALID_EXT:\n",
        "                return True, e.name\n",
        "    return False, None\n",
        "\n",
        "for split in [\"train\",\"val\",\"test\"]:\n",
        "    p = Path(f\"data/{split}/chart\")\n",
        "    ok, sample = has_any_file(p)\n",
        "    print(split, \"chart ->\", ok, sample)\n",
        "    p = Path(f\"data/{split}/nonchart\")\n",
        "    ok, sample = has_any_file(p)\n",
        "    print(split, \"nonchart ->\", ok, sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# YOLOv11 ë¶„ë¥˜ í•™ìŠµ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1756277631567
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[0] Sanity scan (ì›ë³¸ data)\n",
            "[train/chart    ] exists=True  files=18317\n",
            "[train/nonchart ] exists=True  files=18317\n",
            "[val/chart    ] exists=True  files=1056\n",
            "[val/nonchart ] exists=True  files=1056\n",
            "[test/chart    ] exists=True  files=1509\n",
            "[test/nonchart ] exists=True  files=1509\n",
            "\n",
            "[build_tiny] from /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/data -> /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/data_tiny\n",
            "  train/chart: 2000 files\n",
            "  train/nonchart: 2000 files\n",
            "  val/chart: 200 files\n",
            "  val/nonchart: 200 files\n",
            "  test/chart: 200 files\n",
            "  test/nonchart: 200 files\n",
            "âœ… data_tiny ready.\n",
            "\n",
            "[1] Train (data_tiny, epochs=2)\n",
            "Ultralytics 8.3.186 ğŸš€ Python-3.12.11 torch-2.8.0+cu128 CUDA:0 (NVIDIA H100 NVL, 95248MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=128, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/data_tiny, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=2, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11s-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=cls_smoke_tiny2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=2, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/classify/cls_smoke_tiny2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=0, workspace=None\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/data_tiny/train... found 4000 images in 2 classes âœ… \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/data_tiny/val... found 400 images in 2 classes âœ… \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/data_tiny/test... found 400 images in 2 classes âœ… \n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
            "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
            "  9                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
            " 10                  -1  1    660482  ultralytics.nn.modules.head.Classify         [512, 2]                      \n",
            "YOLO11s-cls summary: 86 layers, 5,445,570 parameters, 5,445,570 gradients, 12.1 GFLOPs\n",
            "Transferred 234/236 items from pretrained weights\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "WARNING âš ï¸ Classification `cache_ram` training has known memory leak in https://github.com/ultralytics/ultralytics/issues/9824, setting `cache_ram=False`.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1.6Â±0.7 MB/s, size: 33.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/data_tiny/train... 4000 images, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 4000/4000 214.6it/s 18.6s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/data_tiny/train.cache\n",
            "WARNING âš ï¸ Classification `cache_ram` training has known memory leak in https://github.com/ultralytics/ultralytics/issues/9824, setting `cache_ram=False`.\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1.9Â±0.9 MB/s, size: 34.2 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/data_tiny/val... 400 images, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 400/400 313.1it/s 1.3s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/data_tiny/val.cache\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.001), 40 bias(decay=0.0)\n",
            "Image sizes 224 train, 224 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/classify/cls_smoke_tiny2\u001b[0m\n",
            "Starting training for 2 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K        1/2      3.01G     0.1835         32        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 0.11it/s 4:48\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 0.09it/s 23.4s\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K        2/2      3.51G    0.00775         32        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 0.11it/s 4:40\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 0.08it/s 23.7s\n",
            "                   all          1          1\n",
            "\n",
            "2 epochs completed in 0.171 hours.\n",
            "Optimizer stripped from runs/classify/cls_smoke_tiny2/weights/last.pt, 11.0MB\n",
            "Optimizer stripped from runs/classify/cls_smoke_tiny2/weights/best.pt, 11.0MB\n",
            "\n",
            "Validating runs/classify/cls_smoke_tiny2/weights/best.pt...\n",
            "Ultralytics 8.3.186 ğŸš€ Python-3.12.11 torch-2.8.0+cu128 CUDA:0 (NVIDIA H100 NVL, 95248MiB)\n",
            "YOLO11s-cls summary (fused): 47 layers, 5,436,690 parameters, 0 gradients, 12.0 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/data_tiny/train... found 4000 images in 2 classes âœ… \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/data_tiny/val... found 400 images in 2 classes âœ… \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/data_tiny/test... found 400 images in 2 classes âœ… \n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 0.09it/s 21.8s\n",
            "                   all          1          1\n",
            "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/classify/cls_smoke_tiny2\u001b[0m\n",
            "\n",
            "[2] Validate on test split (data_tiny)\n",
            "Ultralytics 8.3.186 ğŸš€ Python-3.12.11 torch-2.8.0+cu128 CUDA:0 (NVIDIA H100 NVL, 95248MiB)\n",
            "YOLO11s-cls summary (fused): 47 layers, 5,436,690 parameters, 0 gradients, 12.0 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/data_tiny/train... found 4000 images in 2 classes âœ… \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/data_tiny/val... found 400 images in 2 classes âœ… \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/data_tiny/test... found 400 images in 2 classes âœ… \n",
            "WARNING âš ï¸ Classification `cache_ram` training has known memory leak in https://github.com/ultralytics/ultralytics/issues/9824, setting `cache_ram=False`.\n",
            "\u001b[34m\u001b[1mtest: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2.4Â±1.5 MB/s, size: 41.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtest: \u001b[0mScanning /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/data_tiny/test... 400 images, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 400/400 286.9it/s 1.4s\n",
            "\u001b[34m\u001b[1mtest: \u001b[0mNew cache created: /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/data_tiny/test.cache\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.19it/s 21.5s\n",
            "                   all          1          1\n",
            "Speed: 0.0ms preprocess, 0.3ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/classify/cls_smoke_tiny22\u001b[0m\n",
            "test metrics: {'metrics/accuracy_top1': 1.0, 'metrics/accuracy_top5': 1.0, 'fitness': 1.0}\n",
            "\n",
            "[OK] í”„ë¦¬í”Œë¼ì´íŠ¸ ìŠ¤ëª¨í¬ ì™„ë£Œ. confusion_matrix.pngëŠ” runs/classify/cls_smoke_tiny/ ì— ì €ì¥ë©ë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "# === Preflight Smoke Test for YOLO11s Classification ===\n",
        "# - ë””ë ‰í„°ë¦¬/í™•ì¥ì ì ê²€\n",
        "# - ì‘ì€ ì„œë¸Œì…‹(data_tiny) ìƒì„± (ê° split, ê° í´ë˜ìŠ¤ Nì¥)\n",
        "# - 1~2 epoch ìŠ¤ëª¨í¬ í•™ìŠµ/ê²€ì¦ (workers=0ë¡œ symlink/ë§ˆìš´íŠ¸ ì´ìŠˆë„ ì ê²€)\n",
        "import os, random, shutil\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "DATA_DIR = str(Path(\"data\").resolve())   # ì›ë³¸ ë°ì´í„° ë£¨íŠ¸ (train/val/test í•˜ìœ„ì— chart/nonchart)\n",
        "TINY_DIR = str(Path(\"data_tiny\").resolve())\n",
        "VALID_EXT = {\".bmp\",\".jpg\",\".jpeg\",\".png\",\".tif\",\".tiff\",\".dng\",\".webp\",\".mpo\"}\n",
        "\n",
        "PER_SPLIT_N = {\"train\": 2000, \"val\": 200, \"test\": 200}  # í•„ìš”ì‹œ 400/80/80 â†’ 1000/200/200 ë“±ìœ¼ë¡œ ì¡°ì ˆ\n",
        "\n",
        "def list_flat_fast(p: Path):\n",
        "    files = []\n",
        "    with os.scandir(p) as it:\n",
        "        for e in it:\n",
        "            if e.is_file() and Path(e.name).suffix.lower() in VALID_EXT:\n",
        "                files.append(p / e.name)\n",
        "    return files\n",
        "\n",
        "def sanity_scan(root: str):\n",
        "    ok = True\n",
        "    for split in [\"train\",\"val\",\"test\"]:\n",
        "        for cls in [\"chart\",\"nonchart\"]:\n",
        "            d = Path(root) / split / cls\n",
        "            exists = d.exists() and d.is_dir()\n",
        "            cnt = len(list_flat_fast(d)) if exists else 0\n",
        "            print(f\"[{split}/{cls:9s}] exists={exists}  files={cnt}\")\n",
        "            if not exists or cnt == 0:\n",
        "                ok = False\n",
        "    return ok\n",
        "\n",
        "def build_tiny(src_root: str, dst_root: str):\n",
        "    print(f\"\\n[build_tiny] from {src_root} -> {dst_root}\")\n",
        "    for split in [\"train\",\"val\",\"test\"]:\n",
        "        for cls in [\"chart\",\"nonchart\"]:\n",
        "            src = Path(src_root) / split / cls\n",
        "            dst = Path(dst_root) / split / cls\n",
        "            dst.mkdir(parents=True, exist_ok=True)\n",
        "            files = list_flat_fast(src)\n",
        "            if len(files) == 0:\n",
        "                raise RuntimeError(f\"{src} has no valid images\")\n",
        "            k = min(PER_SPLIT_N[split], len(files))\n",
        "            pick = random.sample(files, k) if len(files) > k else files\n",
        "            for f in pick:\n",
        "                out = dst / f.name\n",
        "                if not out.exists():\n",
        "                    shutil.copy2(f, out)\n",
        "            print(f\"  {split}/{cls}: {k} files\")\n",
        "    print(\"âœ… data_tiny ready.\")\n",
        "\n",
        "# 0) ë””ë ‰í„°ë¦¬/í™•ì¥ì ì ê²€\n",
        "print(\"\\n[0] Sanity scan (ì›ë³¸ data)\")\n",
        "ok = sanity_scan(DATA_DIR)\n",
        "if not ok:\n",
        "    raise SystemExit(\"âŒ ì¼ë¶€ split/classê°€ ë¹„ì–´ìˆê±°ë‚˜ í™•ì¥ì ì´ìŠˆê°€ ìˆìŠµë‹ˆë‹¤. ìœ„ ë¡œê·¸ë¥¼ ë¨¼ì € í•´ê²°í•˜ì„¸ìš”.\")\n",
        "\n",
        "# 1) ì´ˆì†Œí˜• ì„œë¸Œì…‹ ìƒì„± (ë””ë ‰í„°ë¦¬ listingì´ ëŠë ¤ë„ ì†ŒëŸ‰ë§Œ ë³µì‚¬í•´ì„œ ë¹ ë¥´ê²Œ í…ŒìŠ¤íŠ¸)\n",
        "if Path(TINY_DIR).exists():\n",
        "    shutil.rmtree(TINY_DIR)\n",
        "build_tiny(DATA_DIR, TINY_DIR)\n",
        "\n",
        "# 2) ìŠ¤ëª¨í¬ í•™ìŠµ(1~2 epoch) + í…ŒìŠ¤íŠ¸ ê²€ì¦\n",
        "#    - workers=0: symlink/ë§ˆìš´íŠ¸ ë¬¸ì œë¥¼ ë¹¨ë¦¬ ë“œëŸ¬ë‚´ê¸° ìœ„í•¨\n",
        "#    - epochs=2: ê³¼ì í•©ê¹Œì§€ëŠ” ì•„ë‹ˆê³  íŒŒì´í”„ë¼ì¸ ì •ìƒë™ì‘ í™•ì¸ìš©\n",
        "model = YOLO(\"yolo11s-cls.pt\")\n",
        "print(\"\\n[1] Train (data_tiny, epochs=2)\")\n",
        "model.train(\n",
        "    data=TINY_DIR, imgsz=224,\n",
        "    epochs=2, batch=128, workers=0,            # âœ… workers=0ë¡œ ë¨¼ì € ì ê²€\n",
        "    name=\"cls_smoke_tiny\",\n",
        "    cache=True, amp=True, cos_lr=True, patience=2,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"\\n[2] Validate on test split (data_tiny)\")\n",
        "metrics = model.val(data=TINY_DIR, split=\"test\", imgsz=224, workers=0)\n",
        "print(\"test metrics:\", metrics.results_dict)\n",
        "\n",
        "print(\"\\n[OK] í”„ë¦¬í”Œë¼ì´íŠ¸ ìŠ¤ëª¨í¬ ì™„ë£Œ. confusion_matrix.pngëŠ” runs/classify/cls_smoke_tiny/ ì— ì €ì¥ë©ë‹ˆë‹¤.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1756278331043
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Train] batch=256, epochs=30, imgsz=224, workers=16\n",
            "Ultralytics 8.3.186 ğŸš€ Python-3.12.11 torch-2.8.0+cu128 CUDA:0 (NVIDIA H100 NVL, 95248MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=256, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/data_tiny, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11s-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=chart_nonchart_cls_y11s_1756278129, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/classify/chart_nonchart_cls_y11s_1756278129, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=16, workspace=None\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/data_tiny/train... found 4000 images in 2 classes âœ… \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/data_tiny/val... found 400 images in 2 classes âœ… \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/data_tiny/test... found 400 images in 2 classes âœ… \n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
            "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
            "  9                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
            " 10                  -1  1    660482  ultralytics.nn.modules.head.Classify         [512, 2]                      \n",
            "YOLO11s-cls summary: 86 layers, 5,445,570 parameters, 5,445,570 gradients, 12.1 GFLOPs\n",
            "Transferred 234/236 items from pretrained weights\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "WARNING âš ï¸ Classification `cache_ram` training has known memory leak in https://github.com/ultralytics/ultralytics/issues/9824, setting `cache_ram=False`.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1.4Â±0.5 MB/s, size: 33.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/data_tiny/train... 4000 images, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 4000/4000 4814122.2it/s 0.0s.0s\n",
            "WARNING âš ï¸ Classification `cache_ram` training has known memory leak in https://github.com/ultralytics/ultralytics/issues/9824, setting `cache_ram=False`.\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2.2Â±0.5 MB/s, size: 34.2 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/data_tiny/val... 400 images, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 400/400 502763.4it/s 0.0s0s\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.002), 40 bias(decay=0.0)\n",
            "Image sizes 224 train, 224 val\n",
            "Using 16 dataloader workers\n",
            "Logging results to \u001b[1mruns/classify/chart_nonchart_cls_y11s_1756278129\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       1/30      5.69G     0.2904        160        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16/16 1.0it/s 15.5ss\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.0it/s 0.2s\n",
            "                   all      0.998          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       2/30      6.46G     0.0191        160        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16/16 1.7it/s 9.3ss\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 49.9it/s 0.0s\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       3/30      6.47G   0.006468        160        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16/16 1.4it/s 11.3ss\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 50.6it/s 0.0s\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       4/30      6.47G    0.01448        160        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16/16 1.3it/s 11.9ss\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 49.7it/s 0.0s\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       5/30      6.47G     0.0162        160        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16/16 1.4it/s 11.8ss\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 49.4it/s 0.0s\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       6/30      6.47G    0.02687        160        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16/16 1.2it/s 13.2ss\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 50.0it/s 0.0s\n",
            "                   all      0.765          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       7/30      6.47G    0.04803        160        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16/16 1.3it/s 12.8ss\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 49.4it/s 0.0s\n",
            "                   all        0.9          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       8/30      6.47G    0.03387        160        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16/16 1.2it/s 13.4ss\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 49.6it/s 0.0s\n",
            "                   all      0.995          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       9/30      6.47G     0.0256        160        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16/16 1.3it/s 12.1ss\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 50.3it/s 0.0s\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      10/30      6.47G    0.02759        160        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16/16 1.3it/s 12.0ss\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 49.8it/s 0.0s\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      11/30      6.47G    0.01334        160        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16/16 1.3it/s 12.0ss\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 50.1it/s 0.0s\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      12/30      6.47G     0.0241        160        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16/16 1.3it/s 12.1ss\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 49.8it/s 0.0s\n",
            "                   all      0.998          1\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 10 epochs. Best results observed at epoch 2, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=10) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "12 epochs completed in 0.044 hours.\n",
            "Optimizer stripped from runs/classify/chart_nonchart_cls_y11s_1756278129/weights/last.pt, 11.0MB\n",
            "Optimizer stripped from runs/classify/chart_nonchart_cls_y11s_1756278129/weights/best.pt, 11.0MB\n",
            "\n",
            "Validating runs/classify/chart_nonchart_cls_y11s_1756278129/weights/best.pt...\n",
            "Ultralytics 8.3.186 ğŸš€ Python-3.12.11 torch-2.8.0+cu128 CUDA:0 (NVIDIA H100 NVL, 95248MiB)\n",
            "YOLO11s-cls summary (fused): 47 layers, 5,436,690 parameters, 0 gradients, 12.0 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/data_tiny/train... found 4000 images in 2 classes âœ… \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/data_tiny/val... found 400 images in 2 classes âœ… \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/data_tiny/test... found 400 images in 2 classes âœ… \n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 50.2it/s 0.0s\n",
            "                   all          1          1\n",
            "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/classify/chart_nonchart_cls_y11s_1756278129\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# === YOLO11s Classification: train -> val -> test -> export ===\n",
        "# H100 NVL ê¸°ì¤€ ì„¤ì •. OOM ë‚˜ë©´ BATCHë¥¼ 256 -> 128 -> 64ë¡œ ë‚®ì¶°ì„œ ì¬ì‹œë„.\n",
        "\n",
        "import os, glob, json, shutil, pathlib, time\n",
        "from ultralytics import YOLO\n",
        "\n",
        "DATA_YAML = (Path(\"data_tiny\").resolve()) # TINY_DIR ê²½ë¡œ ì‚¬ìš©\n",
        "MODEL     = \"yolo11s-cls.pt\"          # ì‚¬ì „í•™ìŠµ ëª¨ë¸\n",
        "IMGSZ     = 224                       # ë¶„ë¥˜ ê¸°ë³¸ í•´ìƒë„\n",
        "EPOCHS    = 30                        # ë¨¼ì € 30epoch ìŠ¤ëª¨í¬ â†’ ê°œì„  ì‹œ 50~100\n",
        "WORKERS   = min(os.cpu_count() or 8, 16)\n",
        "SEED      = 42\n",
        "\n",
        "# H100ì´ë©´ 256ë„ ì—¬ìœ . OOMì‹œ 128/64ë¡œ ë‚®ì¶° ì¬ì‹¤í–‰.\n",
        "BATCH_CANDIDATES = [256, 128, 64]\n",
        "\n",
        "run_name = f\"chart_nonchart_cls_y11s_{int(time.time())}\"\n",
        "\n",
        "def try_train(batch):\n",
        "    print(f\"\\n[Train] batch={batch}, epochs={EPOCHS}, imgsz={IMGSZ}, workers={WORKERS}\")\n",
        "    model = YOLO(MODEL)\n",
        "    res = model.train(\n",
        "        data=DATA_YAML,\n",
        "        epochs=EPOCHS,\n",
        "        device=0,\n",
        "        imgsz=IMGSZ,\n",
        "        batch=batch,\n",
        "        workers=WORKERS,\n",
        "        name=run_name,\n",
        "        seed=SEED,\n",
        "        cache=True,        # ë””ìŠ¤í¬ ìºì‹œë¡œ I/O ì¶•ì†Œ\n",
        "        amp=True,          # mixed precision\n",
        "        cos_lr=True,       # cosine LR schedule\n",
        "        patience=10,       # early stopping\n",
        "        plots=True,        # í•™ìŠµ ê³¡ì„ /CM ë“± ì €ì¥\n",
        "        verbose=True,\n",
        "    )\n",
        "    return model, res\n",
        "\n",
        "trained = None\n",
        "for b in BATCH_CANDIDATES:\n",
        "    try:\n",
        "        model, train_res = try_train(b)\n",
        "        trained = (model, train_res)\n",
        "        break\n",
        "    except RuntimeError as e:\n",
        "        if \"CUDA out of memory\" in str(e):\n",
        "            print(f\"OOM at batch={b}, retrying with smaller batch...\")\n",
        "            continue\n",
        "        raise\n",
        "\n",
        "assert trained is not None, \"Training failed at all batch sizes\"\n",
        "model, train_res = trained"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Test & ê²°ê³¼ íŒŒì¼/ëª¨ë¸ ì €ì¥"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Best Modelë¡œ Test ì§„í–‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1756278410271
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TEST] using weights: runs/classify/chart_nonchart_cls_y11s_1756278129/weights/best.pt\n",
            "Ultralytics 8.3.186 ğŸš€ Python-3.12.11 torch-2.8.0+cu128 CUDA:0 (NVIDIA H100 NVL, 95248MiB)\n",
            "YOLO11s-cls summary (fused): 47 layers, 5,436,690 parameters, 0 gradients, 12.0 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/data_tiny/train... found 4000 images in 2 classes âœ… \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/data_tiny/val... found 400 images in 2 classes âœ… \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/data_tiny/test... found 400 images in 2 classes âœ… \n",
            "\u001b[34m\u001b[1mtest: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2.1Â±1.5 MB/s, size: 41.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtest: \u001b[0mScanning /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/data_tiny/test... 400 images, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 400/400 1088722.6it/s 0.0s0s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 17.8it/s 1.4s\n",
            "                   all      0.995          1\n",
            "Speed: 0.0ms preprocess, 0.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/classify/val\u001b[0m\n",
            "test metrics: {'metrics/accuracy_top1': 0.9950000047683716, 'metrics/accuracy_top5': 1.0, 'fitness': 0.9975000023841858}\n",
            "âœ… saved: runs/classify/chart_nonchart_cls_y11s_1756278129/summaries/test_summary.json\n"
          ]
        }
      ],
      "source": [
        "# === TEST with best.pt ===\n",
        "import os, glob, json, pathlib\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# 1) ìµœì‹  run í´ë”/ê°€ì¤‘ì¹˜ ì°¾ê¸°\n",
        "runs = sorted(glob.glob(f\"runs/classify/{run_name}*\"), key=os.path.getmtime)\n",
        "assert runs, \"run í´ë”ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\"\n",
        "run_dir = pathlib.Path(runs[-1])\n",
        "w_best  = run_dir/\"weights\"/\"best.pt\"\n",
        "w_last  = run_dir/\"weights\"/\"last.pt\"\n",
        "use_w   = w_best if w_best.exists() else w_last\n",
        "assert use_w.exists(), \"best/last ê°€ì¤‘ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
        "\n",
        "# 2) Best Weight ì‚¬ìš©í•œ best modelë¡œ í…ŒìŠ¤íŠ¸ ì§„í–‰\n",
        "print(f\"[TEST] using weights: {use_w}\")\n",
        "model_for_test = YOLO(str(use_w))\n",
        "\n",
        "test_res = model_for_test.val(\n",
        "    data=DATA_YAML,\n",
        "    split=\"test\",\n",
        "    imgsz=IMGSZ,\n",
        "    workers=WORKERS,\n",
        ")\n",
        "\n",
        "print(\"test metrics:\", test_res.results_dict)\n",
        "\n",
        "summary_dir = run_dir / \"summaries\"\n",
        "summary_dir.mkdir(parents=True, exist_ok=True)\n",
        "with open(summary_dir / \"test_summary.json\", \"w\") as f:\n",
        "    json.dump({k: float(v) for k, v in test_res.results_dict.items()}, f, indent=2)\n",
        "\n",
        "print(\"âœ… saved:\", summary_dir / \"test_summary.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## ì‚°ì¶œë¬¼ packaging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1756278466050
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“¦ Packed: /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/model_artifact\n"
          ]
        }
      ],
      "source": [
        "import os, json, shutil, glob, pathlib, time\n",
        "from ultralytics import __version__ as ulty_ver\n",
        "\n",
        "# 1) ìµœì‹  run í´ë”/ê°€ì¤‘ì¹˜ ì°¾ê¸°\n",
        "runs = sorted(glob.glob(f\"runs/classify/{run_name}*\"), key=os.path.getmtime)\n",
        "assert runs, \"run í´ë”ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\"\n",
        "run_dir = pathlib.Path(runs[-1])\n",
        "w_best  = run_dir/\"weights\"/\"best.pt\"\n",
        "w_last  = run_dir/\"weights\"/\"last.pt\"\n",
        "use_w   = w_best if w_best.exists() else w_last\n",
        "assert use_w.exists(), \"best/last ê°€ì¤‘ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
        "\n",
        "# 2) í…ŒìŠ¤íŠ¸ ìš”ì•½(ìˆìœ¼ë©´)ì™€ data.yaml ê°™ì€ ë ˆí¼ëŸ°ìŠ¤ë„ ë¬¶ê¸°\n",
        "artifact_dir = pathlib.Path(\"model_artifact\")\n",
        "if artifact_dir.exists():\n",
        "    shutil.rmtree(artifact_dir)\n",
        "(artifact_dir/\"weights\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "shutil.copy2(use_w, artifact_dir/\"weights\"/use_w.name)\n",
        "for extra in [\"data/data.yaml\", str(run_dir/\"summaries\"/\"test_summary.json\")]:\n",
        "    p = pathlib.Path(extra)\n",
        "    if p.exists():\n",
        "        dst = artifact_dir/p.name if p.suffix else artifact_dir/p.parts[-1]\n",
        "        try:\n",
        "            shutil.copy2(p, dst)\n",
        "        except IsADirectoryError:\n",
        "            shutil.copytree(p, artifact_dir/p.name, dirs_exist_ok=True)\n",
        "\n",
        "# 3) ë©”íƒ€ë°ì´í„° ê¸°ë¡(ì‘ì—… ì¬í˜„ìš©)\n",
        "meta = {\n",
        "    \"task\": \"image-classification\",\n",
        "    \"classes\": {0:\"chart\", 1:\"nonchart\"},\n",
        "    \"imgsz\": 224,\n",
        "    \"epochs\": 30,\n",
        "    \"ultralytics_version\": ulty_ver,\n",
        "    \"source_run\": str(run_dir),\n",
        "    \"weight_file\": use_w.name,\n",
        "}\n",
        "with open(artifact_dir/\"model_card.json\",\"w\") as f:\n",
        "    json.dump(meta, f, indent=2)\n",
        "print(\"ğŸ“¦ Packed:\", artifact_dir.resolve())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## ML ì›Œí¬ìŠ¤í˜ì´ìŠ¤ì— ëª¨ë¸ ë“±ë¡"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1756279214963
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Overriding of current TracerProvider is not allowed\n",
            "Overriding of current LoggerProvider is not allowed\n",
            "Overriding of current MeterProvider is not allowed\n",
            "Attempting to instrument while already instrumented\n",
            "Attempting to instrument while already instrumented\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Registered model: yolo11-chart-binary-cls v2\n"
          ]
        }
      ],
      "source": [
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.ai.ml.entities import Model\n",
        "\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# .env\n",
        "load_dotenv()\n",
        "\n",
        "# get environment variables\n",
        "sub_id = os.getenv(\"SUBSCRIPTION_ID\")\n",
        "rg = os.getenv(\"RESOURCE_GROUP\")\n",
        "ws_name = os.getenv(\"WORKSPACE_NAME\")\n",
        "\n",
        "# (A) êµ¬ë…/ë¦¬ì†ŒìŠ¤/WSë¥¼ ì§ì ‘ ì§€ì •\n",
        "SUBSCRIPTION_ID = sub_id\n",
        "RESOURCE_GROUP  = rg\n",
        "WORKSPACE_NAME  = ws_name\n",
        "\n",
        "# (B) í˜¹ì€ config.jsonì´ ë…¸íŠ¸ë¶ì— ì„¸íŒ…ë˜ì–´ ìˆë‹¤ë©´:\n",
        "# from azure.ai.ml import MLClient\n",
        "# ml_client = MLClient.from_config()\n",
        "\n",
        "ml_client = MLClient(\n",
        "    DefaultAzureCredential(),\n",
        "    SUBSCRIPTION_ID,\n",
        "    RESOURCE_GROUP,\n",
        "    WORKSPACE_NAME,\n",
        ")\n",
        "\n",
        "model_name = \"yolo11-chart-binary-cls\"   # ì›í•˜ëŠ” ê³ ì • ì´ë¦„\n",
        "model = Model(\n",
        "    name=model_name,\n",
        "    path=str(artifact_dir),             # í´ë” í†µì§¸ë¡œ ì—…ë¡œë“œ\n",
        "    type=\"custom_model\",                # .pt/onnx ë¬¶ìŒì´ë©´ custom_model ì í•©\n",
        "    description=\"YOLO11s classification (chart vs nonchart). Includes weights and metadata.\",\n",
        "    tags={\n",
        "        \"task\":\"classification\",\n",
        "        \"backbone\":\"yolo11s-cls\",\n",
        "        \"classes\":\"chart,nonchart\",\n",
        "    },\n",
        "    properties={\n",
        "        \"ultralytics_version\": ulty_ver,\n",
        "        \"imgsz\":\"224\",\n",
        "    }\n",
        ")\n",
        "\n",
        "registered = ml_client.models.create_or_update(model)\n",
        "print(f\"âœ… Registered model: {registered.name} v{registered.version}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### (Optional) ONNX/TorchScript ë‚´ë³´ë‚´ê¸°\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1756279318218
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[EXPORT] onnx (fp32)\n",
            "Ultralytics 8.3.186 ğŸš€ Python-3.12.11 torch-2.8.0+cu128 CPU (AMD EPYC 9V84 96-Core Processor)\n",
            "YOLO11s-cls summary (fused): 47 layers, 5,436,690 parameters, 0 gradients, 12.0 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs/classify/chart_nonchart_cls_y11s_1756278129/weights/best.pt' with input shape (1, 3, 224, 224) BCHW and output shape(s) (1, 2) (10.5 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx>=1.12.0,<1.18.0', 'onnxslim>=0.1.59', 'onnxruntime-gpu'] not found, attempting AutoUpdate...\n",
            "Requirement already satisfied: onnx<1.18.0,>=1.12.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (1.17.0)\n",
            "Requirement already satisfied: onnxslim>=0.1.59 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (0.1.64)\n",
            "Requirement already satisfied: onnxruntime-gpu in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (1.22.0)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from onnx<1.18.0,>=1.12.0) (4.25.8)\n",
            "Requirement already satisfied: numpy>=1.20 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from onnx<1.18.0,>=1.12.0) (1.23.5)\n",
            "Requirement already satisfied: colorama in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from onnxslim>=0.1.59) (0.4.6)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from onnxslim>=0.1.59) (1.13.3)\n",
            "Requirement already satisfied: packaging in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from onnxslim>=0.1.59) (25.0)\n",
            "Requirement already satisfied: coloredlogs in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from onnxruntime-gpu) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from onnxruntime-gpu) (25.2.10)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from sympy>=1.13.3->onnxslim>=0.1.59) (1.3.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from coloredlogs->onnxruntime-gpu) (10.0)\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 7.0s\n",
            "WARNING âš ï¸ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.0 opset 19...\n",
            "WARNING âš ï¸ \u001b[34m\u001b[1mONNX:\u001b[0m simplifier failure: No module named 'onnxslim'\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 8.3s, saved as 'runs/classify/chart_nonchart_cls_y11s_1756278129/weights/best.onnx' (20.8 MB)\n",
            "\n",
            "Export complete (8.5s)\n",
            "Results saved to \u001b[1m/afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/runs/classify/chart_nonchart_cls_y11s_1756278129/weights\u001b[0m\n",
            "Predict:         yolo predict task=classify model=runs/classify/chart_nonchart_cls_y11s_1756278129/weights/best.onnx imgsz=224  \n",
            "Validate:        yolo val task=classify model=runs/classify/chart_nonchart_cls_y11s_1756278129/weights/best.onnx imgsz=224 data=/afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/data_tiny  \n",
            "Visualize:       https://netron.app\n",
            "[EXPORT] torchscript\n",
            "Ultralytics 8.3.186 ğŸš€ Python-3.12.11 torch-2.8.0+cu128 CPU (AMD EPYC 9V84 96-Core Processor)\n",
            "YOLO11s-cls summary (fused): 47 layers, 5,436,690 parameters, 0 gradients, 12.0 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs/classify/chart_nonchart_cls_y11s_1756278129/weights/best.pt' with input shape (1, 3, 224, 224) BCHW and output shape(s) (1, 2) (10.5 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.8.0+cu128...\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success âœ… 0.7s, saved as 'runs/classify/chart_nonchart_cls_y11s_1756278129/weights/best.torchscript' (20.9 MB)\n",
            "\n",
            "Export complete (0.8s)\n",
            "Results saved to \u001b[1m/afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/runs/classify/chart_nonchart_cls_y11s_1756278129/weights\u001b[0m\n",
            "Predict:         yolo predict task=classify model=runs/classify/chart_nonchart_cls_y11s_1756278129/weights/best.torchscript imgsz=224  \n",
            "Validate:        yolo val task=classify model=runs/classify/chart_nonchart_cls_y11s_1756278129/weights/best.torchscript imgsz=224 data=/afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/yolov11/data_tiny  \n",
            "Visualize:       https://netron.app\n",
            "\n",
            "Done. Exported Artifacts in: runs/classify/chart_nonchart_cls_y11s_1756278129\n"
          ]
        }
      ],
      "source": [
        "best_model = YOLO(str(use_w))\n",
        "print(\"\\n[EXPORT] onnx (fp32)\")\n",
        "best_model.export(format=\"onnx\", imgsz=IMGSZ)\n",
        "print(\"[EXPORT] torchscript\")\n",
        "best_model.export(format=\"torchscript\", imgsz=IMGSZ)\n",
        "\n",
        "print(\"\\nDone. Exported Artifacts in:\", run_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "ONNX: starting export with onnx 1.18.0 opset 19...\n",
        "WARNING âš ï¸ ONNX: simplifier failure: No module named 'onnxslim'\n",
        "ONNX: export success âœ… 12.8s, saved as 'runs/classify/chart_nonchart_cls_y11s_1755796203/weights/best.onnx' (20.8 MB)\n",
        "\n",
        "Export complete (13.0s)\n",
        "Results saved to /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/ultralytics-yolo/runs/classify/chart_nonchart_cls_y11s_1755796203/weights\n",
        "Predict:         yolo predict task=classify model=runs/classify/chart_nonchart_cls_y11s_1755796203/weights/best.onnx imgsz=224  \n",
        "Validate:        yolo val task=classify model=runs/classify/chart_nonchart_cls_y11s_1755796203/weights/best.onnx imgsz=224 data=/afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/ultralytics-yolo/data  \n",
        "Visualize:       https://netron.app\n",
        "[EXPORT] torchscript\n",
        "Ultralytics 8.3.182 ğŸš€ Python-3.12.11 torch-2.8.0+cu128 CPU (AMD EPYC 9V84 96-Core Processor)\n",
        "YOLO11s-cls summary (fused): 47 layers, 5,436,690 parameters, 0 gradients, 12.0 GFLOPs\n",
        "\n",
        "PyTorch: starting from 'runs/classify/chart_nonchart_cls_y11s_1755796203/weights/best.pt' with input shape (1, 3, 224, 224) BCHW and output shape(s) (1, 2) (10.5 MB)\n",
        "\n",
        "TorchScript: starting export with torch 2.8.0+cu128...\n",
        "TorchScript: export success âœ… 0.7s, saved as 'runs/classify/chart_nonchart_cls_y11s_1755796203/weights/best.torchscript' (20.9 MB)\n",
        "\n",
        "Export complete (0.9s)\n",
        "Results saved to /afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/ultralytics-yolo/runs/classify/chart_nonchart_cls_y11s_1755796203/weights\n",
        "Predict:         yolo predict task=classify model=runs/classify/chart_nonchart_cls_y11s_1755796203/weights/best.torchscript imgsz=224  \n",
        "Validate:        yolo val task=classify model=runs/classify/chart_nonchart_cls_y11s_1755796203/weights/best.torchscript imgsz=224 data=/afh/projects/chartvllm-workspace-e50dcc49-4202-489d-ae4f-22f8078e2c70/shared/Users/t-yooyeunkim/ultralytics-yolo/data  \n",
        "Visualize:       https://netron.app\n",
        "\n",
        "Done. Exported Artifacts in: runs/classify/chart_nonchart_cls_y11s_1755796203\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1755800786992
        }
      },
      "outputs": [],
      "source": [
        "import os, time, zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# === ì„¤ì • ===\n",
        "ROOT = Path.cwd()                 # ì§€ê¸ˆ í´ë”ê°€ ultralytics-yoloë¼ë©´ ê·¸ëŒ€ë¡œ\n",
        "EXCLUDE_DIRS = {\n",
        "    \"_foz_cache\", \"data\",         # ë„¤ê°€ ì œì™¸í•´ë‹¬ë¼ í•œ í´ë”\n",
        "    \".ipynb_checkpoints\", \"__pycache__\", \".git\"  # í”í•œ ìºì‹œ/ë©”íƒ€\n",
        "}\n",
        "EXCLUDE_FILES = {\".DS_Store\", \"Thumbs.db\"}       # ìì˜í•œ OS íŒŒì¼\n",
        "PRESERVE_SYMLINKS = True          # ì‹¬ë³¼ë¦­ ë§í¬ ë³´ì¡´(ê¶Œì¥)\n",
        "\n",
        "# === ì¶œë ¥ ZIP ê²½ë¡œ ===\n",
        "ts = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "zip_path = ROOT.parent / f\"{ROOT.name}_{ts}.zip\"\n",
        "\n",
        "def skip_path(rel: Path) -> bool:\n",
        "    # ê²½ë¡œì˜ ì–´ëŠ íŒŒíŠ¸ë¼ë„ ì œì™¸ ë””ë ‰í„°ë¦¬ë©´ ìŠ¤í‚µ\n",
        "    if any(part in EXCLUDE_DIRS for part in rel.parts):\n",
        "        return True\n",
        "    # íŒŒì¼ëª…ë§Œìœ¼ë¡œ ì œì™¸\n",
        "    if rel.name in EXCLUDE_FILES:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "count_files = 0\n",
        "with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "    for p in ROOT.rglob(\"*\"):\n",
        "        if p.is_dir():\n",
        "            continue\n",
        "        rel = p.relative_to(ROOT)\n",
        "\n",
        "        # ì œì™¸ ê·œì¹™\n",
        "        if skip_path(rel):\n",
        "            continue\n",
        "\n",
        "        # ìê¸° ìì‹ (ìƒì„±ì¤‘ì¸ ZIP)ì´ ë£¨íŠ¸ ì•ˆì— ìˆì„ ê²½ìš° ìŠ¤í‚µ(ì§€ê¸ˆì€ ìƒìœ„ì— ë§Œë“¤ë¯€ë¡œ ì•ˆì „)\n",
        "        if p.resolve() == zip_path.resolve():\n",
        "            continue\n",
        "\n",
        "        # ì‹¬ë³¼ë¦­ ë§í¬ ì²˜ë¦¬\n",
        "        if PRESERVE_SYMLINKS and p.is_symlink():\n",
        "            zi = zipfile.ZipInfo(str(rel))\n",
        "            zi.create_system = 3  # UNIX\n",
        "            # 0o120777: symlink íƒ€ì… + í¼ë¯¸ì…˜ -> symlinkë¡œ ë³µì› ê°€ëŠ¥í•œ ë©”íƒ€\n",
        "            zi.external_attr = 0o120777 << 16\n",
        "            # ë§í¬ íƒ€ê¹ƒ ê²½ë¡œë¥¼ ë‚´ìš©ìœ¼ë¡œ ê¸°ë¡(ì¼ë¶€ unzipì€ ì´ê²ƒì„ ì‚¬ìš©í•´ symlink ë³µì›)\n",
        "            zf.writestr(zi, os.readlink(p))\n",
        "        else:\n",
        "            zf.write(p, arcname=rel)\n",
        "\n",
        "        count_files += 1\n",
        "\n",
        "print(f\"âœ… Created: {zip_path}\")\n",
        "print(f\"â€¢ Files added: {count_files}\")\n",
        "try:\n",
        "    print(f\"â€¢ Size: {zip_path.stat().st_size / (1024*1024):.2f} MB\")\n",
        "except Exception:\n",
        "    pass"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "yolo11env2"
    },
    "kernelspec": {
      "display_name": "Python (yolo11env2)",
      "language": "python",
      "name": "yolo11env2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
